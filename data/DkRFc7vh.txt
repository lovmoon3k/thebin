import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import csv
import os
 
folder = 'transactionhashes'
os.makedirs(folder, exist_ok = True)
links = []

url = ["https://bscscan.com/address/0xbce6fc1cfb96b2a09b1a331508c07eefdca1a734",
       "https://bscscan.com/address/0xafa7f6366275e441cf7a13f6d79795c046fb2a54",
       "https://bscscan.com/address/0x2eFEAFBEee89e51E764EE63504C53BF2c0b15825",
       "https://bscscan.com/address/0xf156a0d2f6648c6571827fa66f9e799a11102000",
       "https://bscscan.com/address/0xe757eb2bf1f959eed34ed7617c34a9780111e427",
       "https://bscscan.com/address/0x8ed56ff3c0f80bcb09c4058d655cc74a2f18c711",
       "https://bscscan.com/address/0x95a428d6cfd675a38a13c2db4fd5131a0bed535a",
       "https://bscscan.com/address/0xe473fa2e3fd9c53a76b93a4fe798e650a8283865",
       "https://bscscan.com/address/0x44e30cd757ff2367ff55ecf26d923e837db8e9e4",
       "https://bscscan.com/address/0x9477074079b6003e3b57c7576589a906b5533742",
       "https://bscscan.com/address/0x26DC65885453AB32870893ab97c3aA8b6A329969",
       "https://bscscan.com/address/0x4af3a11d062f060a5d3ea9a2157828f75941c5d7",
       "https://bscscan.com/address/0x78024933c30e21f28c43fcfada9e043373ad5d87",
       "https://bscscan.com/address/0x93e6b828501bd2ae0369faa3cd9b025a39daeec0",
       "https://bscscan.com/address/0xe08aae18a774f83f0a12dd36a7cbee513b80c55a"]
       
       
headers ={"User-Agent":"Mozilla/5.0 (Macintosh; Intel Mac OSX 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko)Chrome/71.0.3578.98 Safari/537.36", 
          "Accept":"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8"
        }
os.chdir(folder)
while True:
    products = []
    ages = []
    product_items_list={}
    dfTotal=pd.DataFrame()
    count=0
    countUrl=0
    for it in url:
        products=[]
        ages=[]
        product_items_list={}
        countUrl=countUrl+1
        r = requests.get(it,headers = headers)
        #print(r)

        soup = BeautifulSoup(r.text, "lxml")
        table = soup.find("table", class_="table table-hover")


        h = table.find_all("td")



        #print("\n")
        for item in h:
                for itemLink in item.find_all('a', href=True, class_='hash-tag text-truncate myFnExpandBox_searchVal'):
                    products.append(itemLink['href'])
                for itemAge in item.find_all('span'):
                    if('ago' in itemAge.get_text()):
                        ages.append(itemAge.get_text())

        #print(products)
        #print(ages)

        dfTotal[countUrl*3-2]=products
        dfTotal[countUrl*3-1]=ages
    dfTotal.to_csv('Transactions-hashes.csv')
    print("Astept 10 secunde")
    time.sleep(10)
    

#TODO:
        #.#



os.chdir(folder)
df = pd.DataFrame(product_items_list).transpose()
print(df[0])
df.to_csv('Transactions-hashes.csv', index= False)
