from pyspark.sql import SparkSession
from pyspark.sql.functions import explode
from pyspark.sql.functions import split
from pyspark.sql.types import StructType, StructField, StringType

spark = SparkSession.builder \
    .appName("count words") \
    .getOrCreate()

userSchema = StructType([StructField("text", StringType(), True)])

wordsDF = spark.readStream.schema(userSchema).format('text').load('/datas8')

splitWordsDF = wordsDF.select(explode(split(wordsDF.text, ",")).alias("word"))

wordCountsDF = splitWordsDF.groupBy("word").count()

wordCountsDF.writeStream \
    .outputMode("complete") \
    .format("console") \
    .start() \
    .awaitTermination()